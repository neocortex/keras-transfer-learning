{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to the model weights file.\n",
    "weights_path = 'vgg16_weights.h5'\n",
    "top_model_weights_path = 'inria_bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/people/train'\n",
    "validation_data_dir = 'data/people/test'\n",
    "nb_train_samples = 1832\n",
    "nb_validation_samples = 741\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# build the VGG16 network\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# load the weights of the VGG16 networks\n",
    "# (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "# note: when there is a complete match between your model definition\n",
    "# and your weight savefile, you can simply call model.load_weights(filename)\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1832 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "bottleneck_features_train = model.predict_generator(generator, nb_train_samples)\n",
    "np.save(open('inria_bottleneck_features_train.npy', 'wb'), bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 741 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples)\n",
    "np.save(open('inria_bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1832 samples, validate on 741 samples\n",
      "Epoch 1/50\n",
      "1832/1832 [==============================] - 6s - loss: 0.6207 - acc: 0.8259 - val_loss: 0.2678 - val_acc: 0.8988\n",
      "Epoch 2/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.2519 - acc: 0.9067 - val_loss: 0.4092 - val_acc: 0.8934\n",
      "Epoch 3/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.1970 - acc: 0.9209 - val_loss: 0.3353 - val_acc: 0.8988\n",
      "Epoch 4/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.1639 - acc: 0.9432 - val_loss: 0.3282 - val_acc: 0.8853\n",
      "Epoch 5/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.1323 - acc: 0.9509 - val_loss: 0.3246 - val_acc: 0.9109\n",
      "Epoch 6/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.1075 - acc: 0.9640 - val_loss: 0.4600 - val_acc: 0.8934\n",
      "Epoch 7/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0899 - acc: 0.9629 - val_loss: 0.4622 - val_acc: 0.9015\n",
      "Epoch 8/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0738 - acc: 0.9743 - val_loss: 1.2786 - val_acc: 0.8138\n",
      "Epoch 9/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0947 - acc: 0.9651 - val_loss: 0.4578 - val_acc: 0.9109\n",
      "Epoch 10/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0742 - acc: 0.9749 - val_loss: 0.6060 - val_acc: 0.8920\n",
      "Epoch 11/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0532 - acc: 0.9814 - val_loss: 0.6298 - val_acc: 0.9028\n",
      "Epoch 12/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0474 - acc: 0.9825 - val_loss: 0.6865 - val_acc: 0.8934\n",
      "Epoch 13/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0470 - acc: 0.9831 - val_loss: 0.7412 - val_acc: 0.8961\n",
      "Epoch 14/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0324 - acc: 0.9869 - val_loss: 0.5941 - val_acc: 0.9082\n",
      "Epoch 15/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0327 - acc: 0.9902 - val_loss: 0.5899 - val_acc: 0.9015\n",
      "Epoch 16/50\n",
      "1832/1832 [==============================] - 6s - loss: 0.0313 - acc: 0.9891 - val_loss: 0.7076 - val_acc: 0.9055\n",
      "Epoch 17/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0297 - acc: 0.9891 - val_loss: 0.5842 - val_acc: 0.9136\n",
      "Epoch 18/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0229 - acc: 0.9918 - val_loss: 0.7137 - val_acc: 0.9082\n",
      "Epoch 19/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0176 - acc: 0.9924 - val_loss: 0.6776 - val_acc: 0.9082\n",
      "Epoch 20/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0164 - acc: 0.9940 - val_loss: 0.8860 - val_acc: 0.8947\n",
      "Epoch 21/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0249 - acc: 0.9924 - val_loss: 0.8651 - val_acc: 0.9001\n",
      "Epoch 22/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0153 - acc: 0.9934 - val_loss: 0.7735 - val_acc: 0.9015\n",
      "Epoch 23/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0110 - acc: 0.9956 - val_loss: 0.8363 - val_acc: 0.9055\n",
      "Epoch 24/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0112 - acc: 0.9951 - val_loss: 0.8369 - val_acc: 0.9069\n",
      "Epoch 25/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0091 - acc: 0.9951 - val_loss: 0.7636 - val_acc: 0.9069\n",
      "Epoch 26/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0178 - acc: 0.9962 - val_loss: 0.8306 - val_acc: 0.9069\n",
      "Epoch 27/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0097 - acc: 0.9962 - val_loss: 0.7641 - val_acc: 0.9069\n",
      "Epoch 28/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0036 - acc: 0.9989 - val_loss: 0.8247 - val_acc: 0.9069\n",
      "Epoch 29/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0167 - acc: 0.9951 - val_loss: 0.8059 - val_acc: 0.9123\n",
      "Epoch 30/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0049 - acc: 0.9984 - val_loss: 0.8926 - val_acc: 0.9069\n",
      "Epoch 31/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0088 - acc: 0.9973 - val_loss: 0.9674 - val_acc: 0.9096\n",
      "Epoch 32/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0094 - acc: 0.9973 - val_loss: 0.9781 - val_acc: 0.9028\n",
      "Epoch 33/50\n",
      "1832/1832 [==============================] - 6s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.9082\n",
      "Epoch 34/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0057 - acc: 0.9984 - val_loss: 0.9523 - val_acc: 0.9069\n",
      "Epoch 35/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0110 - acc: 0.9967 - val_loss: 0.9446 - val_acc: 0.8974\n",
      "Epoch 36/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0036 - acc: 0.9984 - val_loss: 0.9079 - val_acc: 0.9096\n",
      "Epoch 37/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0033 - acc: 0.9995 - val_loss: 0.9043 - val_acc: 0.9136\n",
      "Epoch 38/50\n",
      "1832/1832 [==============================] - 6s - loss: 0.0028 - acc: 0.9989 - val_loss: 1.0222 - val_acc: 0.9028\n",
      "Epoch 39/50\n",
      "1832/1832 [==============================] - 6s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9608 - val_acc: 0.9109\n",
      "Epoch 40/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0026 - acc: 0.9989 - val_loss: 1.0266 - val_acc: 0.9001\n",
      "Epoch 41/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0146 - acc: 0.9978 - val_loss: 1.0337 - val_acc: 0.9028\n",
      "Epoch 42/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0020 - acc: 0.9989 - val_loss: 1.0770 - val_acc: 0.9042\n",
      "Epoch 43/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0103 - acc: 0.9973 - val_loss: 1.0452 - val_acc: 0.9109\n",
      "Epoch 44/50\n",
      "1832/1832 [==============================] - 6s - loss: 0.0021 - acc: 0.9989 - val_loss: 0.9843 - val_acc: 0.9069\n",
      "Epoch 45/50\n",
      "1832/1832 [==============================] - 6s - loss: 0.0059 - acc: 0.9978 - val_loss: 1.0040 - val_acc: 0.8988\n",
      "Epoch 46/50\n",
      "1832/1832 [==============================] - 6s - loss: 7.5320e-04 - acc: 1.0000 - val_loss: 1.0288 - val_acc: 0.9055\n",
      "Epoch 47/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0059 - acc: 0.9984 - val_loss: 1.0895 - val_acc: 0.9028\n",
      "Epoch 48/50\n",
      "1832/1832 [==============================] - 6s - loss: 5.0302e-04 - acc: 1.0000 - val_loss: 1.0322 - val_acc: 0.9042\n",
      "Epoch 49/50\n",
      "1832/1832 [==============================] - 5s - loss: 0.0057 - acc: 0.9984 - val_loss: 1.0311 - val_acc: 0.9001\n",
      "Epoch 50/50\n",
      "1832/1832 [==============================] - 6s - loss: 0.0048 - acc: 0.9984 - val_loss: 1.0081 - val_acc: 0.9028\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(open('inria_bottleneck_features_train.npy', 'rb'))\n",
    "train_labels = np.array([0] * 1218 + [1] * 614)\n",
    "\n",
    "validation_data = np.load(open('inria_bottleneck_features_validation.npy', 'rb'))\n",
    "validation_labels = np.array([0] * 453 + [1] * 288)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          nb_epoch=nb_epoch, batch_size=16,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to the model weights files.\n",
    "weights_path = 'vgg16_weights.h5'\n",
    "top_model_weights_path = 'inria_bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/people/train'\n",
    "validation_data_dir = 'data/people/test'\n",
    "nb_train_samples = 1832\n",
    "nb_validation_samples = 741\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# load the weights of the VGG16 networks\n",
    "# (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "# note: when there is a complete match between your model definition\n",
    "# and your weight savefile, you can simply call model.load_weights(filename)\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model.add(top_model)\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1832 images belonging to 2 classes.\n",
      "Found 741 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  32/1832 [..............................] - ETA: 2501s - loss: 0.1410 - acc: 0.9688    "
     ]
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
